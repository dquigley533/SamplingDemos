{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic canonical sampling recap\n",
    "\n",
    "Consider a system of $N$ particles in $d$ dimensions with positions $\\{\\vec{r}_j\\}$ and momenta $\\{\\vec{p}_j\\}$ that interacts via some Hamiltonian $\\mathcal{H}(\\{\\vec{r}_j\\}) = U(\\{\\vec{r}_j\\}) + K(\\{\\vec{p}_j\\})$. Here $U$ is the potential energy of the system and $K$ the kinetic energy. The positions and momenta collectively define a _microstate_ of the system.\n",
    "\n",
    "We generally don't bother worrying about sampling momentum coordinates and the kinetic energy $K$ since any contribution those make to quantities of interest can be calculated analytically provided we're at equilibrium. Hence I'll just refer to $U$ as \"the energy\" in what follows. \n",
    "\n",
    "We model the \"rest of the universe\" by having this system in contact with a heat bath, i.e. a reservoir of energy at constant temperature $T$. Ability to exchange energy with the heath bath leads to thermal equilibriun in which the system visits configurations with probability:\n",
    "\n",
    "$$ P(\\{\\vec{r}_j\\}) = \\frac{ \\exp{[-\\beta U(\\{\\vec{r}_j\\} )]} }{Z} $$\n",
    "\n",
    "where $\\beta = 1/k_{B}T$ (we'll set $k_B=1$) and $Z$ is the canonical partition function,\n",
    "\n",
    "$$ Z(N,T) = \\int \\exp{[-\\beta U(\\{\\vec{r}_j\\} )]} \\,d\\vec{r}^N $$\n",
    "\n",
    "which in general can't be evaluated directly if $d\\times N$ is more than a few degrees of freedom. \n",
    "\n",
    "At equilibrium this distribution is stationary, and obeys detailed balance. Labelling two microstates (i.e. sets of particle positions) as $A$ and $B$, the detailed balance criterion requires:\n",
    "\n",
    "$$ P(A) P(A\\rightarrow B) = P(B) P(B \\rightarrow A) $$\n",
    "\n",
    "We then seperate the transition probabilities into the probability of generating a trial move from one microstate to another $P_\\textrm{att}$, and the probability of accepting that move $P_\\textrm{acc}$ giving\n",
    "\n",
    "$$ P(A) P_\\textrm{att}(A\\rightarrow B) P_\\textrm{acc}(A\\rightarrow B)  = P(B) P_\\textrm{att}(B\\rightarrow A) P_\\textrm{acc}(B\\rightarrow A) $$\n",
    "\n",
    "Provided that we generate trial moves such that $P_\\textrm{att}(B\\rightarrow A) = P_\\textrm{att}(A\\rightarrow B)$ then *one* choice of $P_\\textrm{acc}$ which satisfies the detailed balance criterion is the Metropolis acceptance rule;\n",
    "\n",
    "\n",
    "$$P_\\textrm{acc} = \\min{[\\exp{(-\\beta \\Delta U}),1]} $$\n",
    "\n",
    "where $\\Delta U$ is the change in energy on making the trial move.\n",
    "\n",
    "We can therefore easily implement a Markov Chain MC procedure to sample the distribution of microstates that are relevant at a particular temperature and use these to compute various physical quantities which depend on ensemble averages (expectations) and variances of quantities that depend on the microstate.\n",
    "\n",
    "Failing to generate forward and reverse moves with equal probability is a common error which has led to some (many) embarassing errors in the literature. Note also that one can sacrifice this condition provided that $P_{\\textrm{acc}}$ is modified accordingly. See configurational bias Monte Carlo methods like force biased MC and Rosenbluth sampling that we won't get into today. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration on a simple bead and spring \"polymer\" model\n",
    "\n",
    "Energy is defined by \"springs\" connecting consecutive beads on the chain, and Van-der-Waals interactions between all non-consecutive beads. See `polymer.py` for details (needs some tidying up and commenting).\n",
    "\n",
    "\n",
    "### Import packages and create some plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the things\n",
    "from polymer import *\n",
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for plotting the configuration of the chain\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def create_chainplot(inchain):\n",
    "    \"\"\"Creates figure and draws a polymer config in 2D\n",
    "\n",
    "    Parameters:\n",
    "    inchain (polymer): polymer object to plot\n",
    "\n",
    "    Returns:\n",
    "    fix, ax : matplotlib figure and axes\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    draw_chains(fig, ax, inchain)\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "def update_chainplot(fig, ax, inchain):\n",
    "    \"\"\"Updates the provided figure and axes with new polymer config\n",
    "\n",
    "    Parameters:\n",
    "    fix, ax : matplotlib figure and axes\n",
    "    inchain (polymer): polymer object to plot\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Clear current axes\n",
    "    ax.cla() \n",
    "    draw_chains(fig, ax, inchain)\n",
    "\n",
    "    # Update for replotting during animation\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "    return\n",
    "\n",
    "def draw_chains(fig, ax, inchain):\n",
    "    \"\"\"Draws a polymer object on the provided figure and axes\n",
    "\n",
    "    Parameters:\n",
    "    fix, ax : matplotlib figure and axes\n",
    "    inchain (polymer): polymer object to plot\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.set(xlim=(-7, 7),ylim=(-7, 7))\n",
    "    circles = list()\n",
    "    for ibead in range(chain.Nbeads):\n",
    "        circles.append(mpatches.Circle(chain.rpos[ibead],radius=chain.R))\n",
    "\n",
    "    for circle in circles:\n",
    "        ax.add_patch(circle)\n",
    "    \n",
    "    xpoints = chain.rpos[:,0]\n",
    "    ypoints = chain.rpos[:,1]\n",
    "    ax.plot(xpoints,ypoints)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_title(\"Current polymer configuration\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and visualise the polymer chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polymer chain\n",
    "Ndims = 2 ; Nbeads = 7\n",
    "chain = polymer(Ndims, Nbeads)\n",
    "\n",
    "# Define bins to be used for plotting (N.B. this assumes I know the energy range I care about in advance!)\n",
    "energy_range = [-6.1, 4.0]\n",
    "bin_edges = np.histogram_bin_edges(energy_range, bins=50)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "\n",
    "# Visualise the initial state of the chain\n",
    "%matplotlib widget\n",
    "fig, ax = create_chainplot(chain)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to implement MCMC sampling on the polymer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mcmc_sweeps(chain, Nsweeps=100, max_disp=0.15, temperature=0.2, sample_int=100):\n",
    "    \"\"\"Performs MCMC on the provided chains for a number of \"sweeps\" where one sweep is on average\n",
    "       an attempt to move each mobile particle once. \n",
    "\n",
    "    Parameters:\n",
    "    chain       : polymer object to sample configurations of\n",
    "    Nsweeps     : number of sweeps to perform\n",
    "    max_disp    : maximum trial displacement (distance)\n",
    "    temperature : temperature of heat bath the polyer is coupled to\n",
    "    sample_int  : interval at which to record samples of energy and end-to-end distance \n",
    "\n",
    "    Returns:\n",
    "    chain       : final state of the polymer\n",
    "    samples     : list of tuples ( energy, end-to-end distance) of recorded samples\n",
    "    ratio       : fraction of moves that were accepted\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "    beta = 1.0/temperature # Store inverse temperature\n",
    "\n",
    "    samples = [] # Initialise samples for the current set of sweeps\n",
    "    acount  = 0  # Number of accepted moves\n",
    "\n",
    "    # Each sweep is one trial per bead on average\n",
    "    for itrial in range(Nsweeps*(chain.Nbeads-1)):\n",
    "\n",
    "        # Randomly choose any bead but the first\n",
    "        ibead = np.random.randint(1,chain.Nbeads)\n",
    "\n",
    "        # Generate random displacement\n",
    "        disp = 2.0*np.random.random_sample(2)-1.0\n",
    "        disp = disp*max_disp\n",
    "\n",
    "        # Make trial move and compute energy change - note we only compute the terms \n",
    "        # in the energy which depend on ibead. See polymer.py\n",
    "        old_local_energy = chain.local_energy(ibead)\n",
    "        chain.rpos[ibead] = chain.rpos[ibead] + disp\n",
    "        new_local_energy = chain.local_energy(ibead)\n",
    "        diff_energy = new_local_energy - old_local_energy\n",
    "\n",
    "        # Accept or reject move\n",
    "        if np.random.sample() < m.exp(-diff_energy*beta):\n",
    "            acount = acount + 1 # Accepted - increment counter\n",
    "        else:\n",
    "            # Restore original chain position \n",
    "            chain.rpos[ibead] = chain.rpos[ibead] - disp\n",
    "\n",
    "        # Sample energy and end-to-end distance every sample_int sweeps\n",
    "        if itrial%sample_int*(chain.Nbeads-1)==0:\n",
    "            samples.append((chain.energy(), chain.end2end()))\n",
    "\n",
    "    ratio = acount/(Nsweeps*(chain.Nbeads-1)) \n",
    "    \n",
    "    # Return current chain, list of samples and acceptance ration\n",
    "    return chain, samples, ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the above Nframes times to generate a set of samples at equilibrium\n",
    "\n",
    "Note the lowest energy hexagon like configuration(s) and extended more linear configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "temp = 0.4       # Temperature at which to sample\n",
    "Nframes = 1000   # Number of frames to run for\n",
    "\n",
    "# I like a progress bar\n",
    "f = IntProgress(min=0, max=Nframes)\n",
    "display(f) # display the bar\n",
    "\n",
    "# Initialise list of samples\n",
    "samples = []\n",
    "\n",
    "# Loop\n",
    "for iframe in range(Nframes):\n",
    "\n",
    "    chain, new_samples, ratio = run_mcmc_sweeps(chain, max_disp=0.1, temperature=temp)\n",
    "    samples += new_samples\n",
    "    update_chainplot(fig, ax, chain)\n",
    "    f.value +=1  # Increment progress bar\n",
    "\n",
    "\n",
    "print(\"Accepted \",round(ratio*100,2),\"% of trial moves during final set of sweeps\")\n",
    "\n",
    "# Save samples to file\n",
    "filename = \"data/mcmc_N\"+str(Nbeads)+\"_d\"+str(Ndims)+\"_T{:1.3}\".format(temp)+\"_Nf\"+str(Nframes)+\".npy\"\n",
    "np.save(filename,np.asarray(samples))\n",
    "print(\"Written samples to : \",filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the samples of energy and end-to-end distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig.clf()\n",
    "\n",
    "energy_samples  = [ sample[0] for sample in samples ]\n",
    "end2end_samples = [ sample[1] for sample in samples ]\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(energy_samples)\n",
    "ax1.set_xlabel(\"Sample\")\n",
    "ax1.set_ylabel(\"Energy U\")\n",
    "ax2.plot(end2end_samples);\n",
    "ax2.set_xlabel(\"Sample\")\n",
    "ax2.set_ylabel(\"End-to-end distance L\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hint via the plot on the right there's two types of configuration, coiled and extended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the histogram of energy samples, find mean energy and heat capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plot\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "counts, bins = np.histogram(energy_samples,bins=bin_edges)\n",
    "plt.hist(bins[:-1], bins, weights=counts)\n",
    "ax.set_xlabel(\"Energy U\")\n",
    "ax.set_ylabel(\"count\")\n",
    "\n",
    "#plt.bar(bins[:-1],counts,width=bin_width,align='edge')\n",
    "#plt.plot(bins[:-1]+0.5*bin_width,counts)\n",
    "#counts, bins = np.histogram(end2end_samples,bins=20)\n",
    "#plt.hist(bins[:-1], bins, weights=counts)\n",
    "\n",
    "# Mean energy\n",
    "mean_U = np.mean(energy_samples)\n",
    "print(\"Mean energy <U> : \", round(mean_U, 3))\n",
    "\n",
    "# Heat capacity (depends on variance of energy, and includes an analytic contribution from the kinetic energy)\n",
    "cv = np.var(energy_samples)/(temp**2) + (Ndims/2)*(Nbeads-1)\n",
    "print(\"Heat capacity   : \", round(cv, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use some existing data from earlier (and longer runs) to extract trends with temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results from runs I did earler from file\n",
    "\n",
    "# Rough data at same quality as above\n",
    "#temperatures = np.arange(0.1, 0.6, 0.1)\n",
    "#run_length = 1000\n",
    "\n",
    "# Better data from longer independent runs on a \"taskfarm\" cluster\n",
    "temperatures = np.arange(0.1, 0.525, 0.05)\n",
    "run_length = 50000\n",
    "\n",
    "# Setup plots\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(1, 3, figsize=(12, 4), constrained_layout=True)\n",
    "\n",
    "ax1.set_xlabel('energy U')\n",
    "ax1.set_ylabel('P(U)')\n",
    "ax1.set_title(\"MCMC energy histograms\")\n",
    "\n",
    "ax2.set_xlabel('temperature')\n",
    "ax2.set_ylabel('<U>')\n",
    "ax2.set_title('Mean energy vs temperature')  \n",
    "\n",
    "ax3.set_xlabel('temperature')\n",
    "ax3.set_ylabel('Cv')\n",
    "ax3.set_title('Heat capacity vs temperature') \n",
    "\n",
    "# Initialise arrays \n",
    "mean_energies   = np.zeros(len(temperatures))\n",
    "mean_errors     = np.zeros(len(temperatures))\n",
    "heat_caps       = np.zeros(len(temperatures))\n",
    "#heat_caps2      = np.zeros(len(temperatures))\n",
    "\n",
    "# Loop over temperatures of interest\n",
    "for itemp, temperature in enumerate(temperatures):\n",
    "    \n",
    "    # Load data\n",
    "    filename = \"data/mcmc_N7_d2_T{:1.3}_Nf{}.npy\".format(temperature,run_length)\n",
    "    samples = np.load(filename).tolist()\n",
    "    energy_samples  = [ sample[0] for sample in samples ]\n",
    "\n",
    "    # Create histogram\n",
    "    counts, bins = np.histogram(energy_samples, bins=bin_edges, density=True)\n",
    "    strlabel = \"T={:1.2}\".format(temperature)\n",
    "    ax1.bar(bins[:-1], counts, width=bin_width, align='edge', label=strlabel)\n",
    "\n",
    "    # Compute mean energy and heat capacity\n",
    "    \n",
    "    # If wanting to interpret the error bars computed here as uncertainties in the estimates\n",
    "    # of mean energy we should sub-sample at an interval greater than the autocorrelation\n",
    "    # time of our samples, and also discard the \"burn in\" or equilibration period.     \n",
    "    #energy_samples  = [ sample[0] for sample in samples[1000:6000:100] ] # Drop equilibration period and subsample\n",
    "\n",
    "    mean_energies[itemp] = np.mean(energy_samples)\n",
    "    mean_errors[itemp] = np.std(energy_samples)/m.sqrt(len(energy_samples))\n",
    "\n",
    "    # Compute heat capacity using the raw samples\n",
    "    heat_caps[itemp] = np.var(energy_samples)/(temperature**2) + (Ndims/2)*(Nbeads-1)\n",
    "\n",
    "    # Compute heat capacity from the discretised (binned) data\n",
    "    #msq_dev = np.zeros(len(bin_edges)-1)\n",
    "    #for ibin, edge in enumerate(bin_edges[:-1]):\n",
    "    #    bin_energy = edge + 0.5*bin_width\n",
    "    #    msq_dev[ibin] = (bin_energy - mean_energies[itemp])**2\n",
    "        \n",
    "    #heat_caps2[itemp] = np.dot(msq_dev, counts)*bin_width/(temperature**2) + (Ndims/2)*(Nbeads-1)\n",
    "\n",
    "# Complete plots using data computed above\n",
    "ax1.legend()\n",
    "ax2.errorbar(temperatures, mean_energies,yerr=mean_errors, fmt='-o')\n",
    "ax3.plot(temperatures, heat_caps, '-o', label='samples')\n",
    "#ax3.plot(temperatures, heat_caps2, '-o', label='histogram')\n",
    "#ax3.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on the results\n",
    "\n",
    "1. The spike in heat capacity at $T=0.1$ here is completely spurious. It shouldn't be there and is the result of a non-ergodic trap. There are multiple configurations of the coiled polymer, but at $T=0.1$ the probability of sampling transitions between them (which go via high energy states very improbable at low $T$) within a finite-length simulation is negligible.\n",
    "\n",
    "2. This is very inefficient as we've run multiple independent simulations that produce overlapping energy histograms. Each energy bin (or _macrostate_) contains microstates that are being wastefully sampled multiple times independently. Ideally we'd want each sample of a configuration to contribution to our statistics at all temperatures were it is relevant without having need to resample it.\n",
    "\n",
    "3. We can so far only create data points for plots against temperature if we've done a simulation at that temperature, not at any temperature in between. \n",
    "\n",
    "See `MUCA.ipynb` for the first example of a method which does better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram reweighting and sample reweighting...\n",
    "\n",
    "Can be used here to produce data at temperatures _close to_ those at which we have explicit samples provided all energies relevant at the temperature of interest are sampled within a simulation we've already got. Limited utility especially as $N$ becomes large and the histograms at each temperature become less broad...\n",
    "\n",
    "Defer demonstration of reweighting until the next notebook where we'll have samples over the full energy range from a single simulation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bits and bobs used for debugging below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity checking two equivalent ways of generating the same histogram\n",
    "samples = np.load(\"data/mcmc_N7_d2_T0.4_Nf1000.npy\").tolist()\n",
    "energy_samples  = [ sample[0] for sample in samples ]\n",
    "end2end_samples = [ sample[1] for sample in samples ]\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Use np.histogram and then plt.bar with the output\n",
    "counts, bins = np.histogram(energy_samples, bins=bin_edges)\n",
    "ax1.bar(bins[:-1], counts, width=bin_width, align='edge', label='T=0.4')\n",
    "ax1.set_xlabel('energy')\n",
    "ax1.set_ylabel('count')\n",
    "ax1.set_title(\"np.histogram plotted with plt.bar\")\n",
    "ax1.legend()\n",
    "\n",
    "# Use plt.hist\n",
    "n, bins, patches = ax2.hist(bins[:-1], bins, weights=counts, label='T=0.4')\n",
    "ax2.set_xlabel('energy')\n",
    "ax2.set_ylabel('count')\n",
    "ax2.set_title(\"plt.hist\")\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
