{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wang-Landau sampling (WL)\n",
    "\n",
    "The Wang-Landau approach recognises that to sample all energies with equal probabilty, we need the probability of sampling an individual microstate to be proportional to the inverse of the density of states at the energy of that microstate. In other words we seek a multicanonical ensemble in which:\n",
    "\n",
    "$$ P\\left(\\{\\vec{r}_j\\}\\right) \\propto \\frac{1}{g\\left(U\\left(\\{\\vec{r}_j\\}\\right)\\right)}$$\n",
    "\n",
    "More succinctly, if the energy of microstate $A$ is $U_A$ we should sample it in proportion to $1/g(U_A)$. Working through the detailed balance condition, the probability to accept a trial move from microstate $A$ to microstate $B$ should be:\n",
    "\n",
    "$$P_\\textrm{acc} = \\min{\\left[\\frac{g(U_A)}{g(U_B)},1\\right]} $$\n",
    "\n",
    "Unfortunately, the density of states in energy isn't known _a priori_ and so like with the basic MUCA procedure we need to compute it iteratively. Wang and Landau proposed the following:\n",
    "\n",
    "1. Set $f=\\mathrm{e}$.\n",
    "2. Start with an estimate of $g(U) = 1$ for all energies.\n",
    "3. Perform an MC simulation with the above acceptance criterion. Upon visiting any energy bin, update the estimate of the density of states $g(U)$ for that bin by multiplying by $f$. Increment a count/histogram of visits to each bin by 1.\n",
    "4. Once a \"flat\" histogram (all bins > 80% of the mean) is acheived, updated $f\\rightarrow \\sqrt{f}$, reset the histogram and repeat from step 3.\n",
    "\n",
    "This continues until $f$ is negligibly different from 1, at which point the procedure is stopped. Quantities which depend only on the energy can be computed directly from $g(U)$. Other quantities must be sampled along with the energy at which the sample was generated in a long simulation with static $g(U)$ and can then reweighted to give averages at any temperature like with the MUCA procedure in the last notebook.\n",
    "\n",
    "The interative refinement of $g(U)$ has subsequently been refined by various authors, e.g. most agree that $f$ should initially be $1.005$ or smaller, and that the flatness criteria on the histogram at each iteration should be tighter. Most groups have their own tweaked procedure.\n",
    "\n",
    "This is illustrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration on our simple bead and spring \"polymer\" model\n",
    "\n",
    "See `Basic_MMC.ipynb` and `polymer.py` for details of the model.\n",
    "\n",
    "One important detail is that we work with the logarithm of $g(U)$ and not the function itself to avoid overflow errors. The density of states can be extremely large. Note also that we only care about the relative magnitude of $g(U)$ so will regularly adjust it downward \n",
    "such that the density of states in the zeroth (lowest energy) bin is 1. \n",
    "\n",
    "### Import packages and create some binning functions functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the things\n",
    "from polymer import *\n",
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_index(x, bin_edges):\n",
    "    \"\"\"Given a list of bin_edges returned from numpy.histogram, and a sampled value x, \n",
    "       return the index of the bin in which x lies. Note that np.digitize is annoying\n",
    "       and I don't like it.\n",
    "\n",
    "    Parameters:\n",
    "    x (float) : sample to assign to a bin\n",
    "    bin_edges : bin edges as returned from numpy.histogram \n",
    "\n",
    "    Returns:\n",
    "    i         : index of bin in which sample lies\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    bin_range = bin_edges[-1] - bin_edges[0]\n",
    "    bin_pos = x - bin_edges[0]\n",
    "\n",
    "    return int( (bin_pos/bin_range)*(len(bin_edges)-1.0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to implement WL sampling on the polymer\n",
    "\n",
    "This requires only minimal changes from that in `MUCA.ipynb`. There is now no bias energy, but we accept reject based only the current estimate of $g(U)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wl_sweeps(chain, bin_edges, wl_hist, wl_logdos, wl_f, Nsweeps=100, max_disp=0.15, sample_int=100):\n",
    "    \"\"\"Performs WL MC on the provided chains for a number of \"sweeps\" where one sweep is on average\n",
    "       an attempt to move each mobile particle once. \n",
    "\n",
    "    Parameters:\n",
    "    chain       : polymer object to sample configurations of\n",
    "    bin_edges   : energy bin edges as returned from numpy.histogram \n",
    "    wl_hist     : current histogram of vists to each energy bin\n",
    "    wl_logdos   : current estimate of g(U) for each energy bin\n",
    "    Nsweeps     : number of sweeps to perform\n",
    "    max_disp    : maximum trial displacement (distance)\n",
    "    temperature : temperature of heat bath the polyer is coupled to\n",
    "    sample_int  : interval at which to record samples of energy and end-to-end distance \n",
    "\n",
    "    Returns:\n",
    "    chain       : final state of the polymer\n",
    "    samples     : list of tuples ( energy, end-to-end distance) of recorded samples\n",
    "    ratio       : fraction of moves that were accepted\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "    # Initialise sampling for the current set of sweeps\n",
    "    samples = []\n",
    "    acount  = 0\n",
    "\n",
    "    # Establish total energy before any moves\n",
    "    old_energy = chain.energy()\n",
    "\n",
    "    # Each sweep is one trial per bead on average\n",
    "    for itrial in range(Nsweeps*(chain.Nbeads-1)):\n",
    "\n",
    "        # Randomly choose any bead but the first\n",
    "        ibead = np.random.randint(1, chain.Nbeads) # first bead never moves\n",
    "\n",
    "        disp = 2.0*np.random.random_sample(2)-1.0\n",
    "        disp = disp*max_disp\n",
    "\n",
    "        # Make trial move and compute energy change - note we only compute the terms \n",
    "        # in the energy which depend on ibead. See polymer.py\n",
    "        old_local_energy = chain.local_energy(ibead)\n",
    "        chain.rpos[ibead] = chain.rpos[ibead] + disp\n",
    "        new_local_energy = chain.local_energy(ibead)\n",
    "\n",
    "        # Find bias energy V for old_energy U before move\n",
    "        ibin = bin_index(old_energy, bin_edges)\n",
    "\n",
    "        # Find bias energy V for new_energy U after move\n",
    "        new_energy = old_energy + ( new_local_energy - old_local_energy )\n",
    "        jbin = bin_index(new_energy, bin_edges)\n",
    "        \n",
    "\n",
    "        # Only compute g(U) change if within limits where defined\n",
    "        if jbin in range (0, len(wl_hist)):\n",
    "\n",
    "            # (Changed for WL) accept based on change in density of states\n",
    "            if np.random.sample() < m.exp(wl_logdos[ibin]-wl_logdos[jbin]):\n",
    "                # accepted\n",
    "                acount = acount + 1\n",
    "                old_energy = new_energy # update old_energy for next move\n",
    "                    \n",
    "            else:\n",
    "                # reject and reset\n",
    "                chain.rpos[ibead] = chain.rpos[ibead] - disp\n",
    "                jbin = ibin # haven't changed bin\n",
    "\n",
    "            # (New for WL) update histogram and density of states\n",
    "            wl_hist[jbin] += 1\n",
    "            wl_logdos[jbin] += wl_f\n",
    "\n",
    "\n",
    "        else:\n",
    "            # reject and reset\n",
    "            chain.rpos[ibead] = chain.rpos[ibead] - disp\n",
    "            \n",
    "        \n",
    "        # Sample energy and end-to-end distance every sample_int sweeps\n",
    "        if itrial%sample_int*(chain.Nbeads-1)==0:\n",
    "            samples.append((chain.energy(), chain.end2end()))\n",
    "\n",
    "        ratio = acount/(Nsweeps*(chain.Nbeads-1)) \n",
    "\n",
    "    return chain, samples, wl_hist, wl_logdos, ratio   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a simulation which uses the above to iteratively refine g(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise wl_simulation\n",
    "Ndims=2 ; Nbeads=7\n",
    "chain = polymer(Ndims = Ndims, Nbeads = Nbeads)\n",
    "\n",
    "# Define energy range and bins\n",
    "energy_range = [-6.1, 4.0]\n",
    "bin_edges = np.histogram_bin_edges(energy_range, bins=50)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "\n",
    "# Initialise histogram and log of DOS\n",
    "wl_hist   = np.zeros(len(bin_edges)-1)\n",
    "wl_logdos = np.zeros(len(bin_edges)-1)\n",
    "\n",
    "# Initialise f, noting it's actually ln(f) that we store and update\n",
    "wl_f = 0.005\n",
    "\n",
    "# Setup some plots\n",
    "%matplotlib widget\n",
    "\n",
    "def label_wl_figure(fig, ax1, ax2, wl_f):\n",
    "    \"\"\" Sets up figures and axis for WL demonstration \"\"\"\n",
    "\n",
    "    ax1.set_xlabel('Energy U')\n",
    "    ax2.set_xlabel('Energy U')\n",
    "    ax1.set_ylabel('Histogram H(U)')\n",
    "    ax2.set_ylabel('ln(g)')\n",
    "    fig.suptitle('Wang Landau iterative DOS refinement', fontsize=16)\n",
    "    ax1.set_title('Current histogram')\n",
    "    ax2.set_title('Refined DOS with log(f) = '+ str(wl_f))\n",
    "\n",
    "    return\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 5))\n",
    "label_wl_figure(fig, ax1, ax2, wl_f)\n",
    "ax1.bar(bin_edges[:-1], wl_hist, width=bin_width, align='edge')\n",
    "ax2.plot(bin_edges[:-1]+0.5*bin_width, wl_logdos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run frames of 100 WL sweeps each until we reach a sufficiently small $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "# Initialise list of samples for current cycle\n",
    "samples = []\n",
    "\n",
    "# It helps to disregard the histogram built up in the period before all bins are visited a few times\n",
    "first_reset = False\n",
    "\n",
    "# When using WL in production we might go as low as machine precision allows here\n",
    "while ( wl_f > 1E-4):\n",
    "    \n",
    "    # Run a number of sweeps of the WL Monte Carlo\n",
    "    chain, new_samples, wl_hist, wl_logdos, ratio = run_wl_sweeps(chain, bin_edges, wl_hist, wl_logdos, wl_f, max_disp=0.1)\n",
    "\n",
    "    # How flat is the histogram, computed as a percentage\n",
    "    flatness = 100*np.min(wl_hist)/np.mean(wl_hist)\n",
    "\n",
    "    # Recreate the above plot with the current data\n",
    "    ax1.cla(), ax2.cla()\n",
    "    label_wl_figure(fig, ax1, ax2, wl_f)\n",
    "    ax1.bar(bin_edges[:-1], wl_hist,   width=bin_width,align='edge')\n",
    "    ax2.plot(bin_edges[:-1]+0.5*bin_width, wl_logdos)  \n",
    "    plt.draw()\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "    # Reset the histogram on the first iteration once all bins visited a few times\n",
    "    if (np.min(wl_hist) > 10):\n",
    "    \n",
    "        if ( first_reset == False ):\n",
    "            first_reset = True\n",
    "            wl_hist = np.zeros(len(bin_edges)-1)\n",
    "    \n",
    "        else:\n",
    "\n",
    "            # Check if we're 80% flat\n",
    "            if flatness > 80.0 :\n",
    "\n",
    "                # Reset the histogram\n",
    "                wl_hist = np.zeros(len(bin_edges)-1)\n",
    "                wl_f = wl_f * 0.5\n",
    "\n",
    "                # Reduce f\n",
    "                print(\"Reduced ln(f) \", wl_f*2 , \" -> \", wl_f)\n",
    "                min_logdos = np.min(wl_logdos)\n",
    "                wl_logdos = wl_logdos - min_logdos\n",
    "\n",
    "                # Save the current weights for use later\n",
    "                filename = 'dos_f'+str(wl_f)+'.txt'\n",
    "                np.savetxt(filename, wl_logdos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use g(U) to compute quantities of interest\n",
    "\n",
    "If all we need is quantities which depend on the distribution of energy at a given temperature then we're done at this point. If our estimate of $g(U)$ if accurate enough, we can compute the energy histogram at any inverse temperature $\\beta$ as:\n",
    "\n",
    "$$ P(U) = g(U) \\exp{[-\\beta U]} $$\n",
    "\n",
    "Hence we can compute mean energy, heat capacity etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy at some particular temperature assuming DOS is perfect\n",
    "\n",
    "# Load DOS I made earlier - comment out to use the one computed above\n",
    "#filename = 'data/dos_f4.8828125e-06.txt'\n",
    "#wl_logdos = np.loadtxt(filename)\n",
    "\n",
    "#temperatures = np.arange(0.1, 0.55, 0.05)\n",
    "temperatures = np.arange(0.1, 0.51, 0.01)\n",
    "\n",
    "# Setup plots\n",
    "%matplotlib inline\n",
    "fig.clf()\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(1, 3, figsize=(12, 4), constrained_layout=True)\n",
    "\n",
    "ax1.set_xlabel('energy U')\n",
    "ax1.set_ylabel('P(U)')\n",
    "ax1.set_title(\"MUCA energy histograms\")\n",
    "\n",
    "ax2.set_xlabel('temperature')\n",
    "ax2.set_ylabel('<U>')\n",
    "ax2.set_title('Mean energy vs temperature')  \n",
    "\n",
    "ax3.set_xlabel('temperature')\n",
    "ax3.set_ylabel('Cv')\n",
    "ax3.set_title('Heat capacity vs temperature') \n",
    "\n",
    "# Initialise arrays \n",
    "mean_energies   = np.zeros(len(temperatures))\n",
    "mean_errors     = np.zeros(len(temperatures))\n",
    "heat_caps       = np.zeros(len(temperatures))\n",
    "\n",
    "# Loop over temperatures of interest\n",
    "for itemp, new_temp in enumerate(temperatures):\n",
    "\n",
    "    beta = 1.0/new_temp\n",
    "    prob = np.zeros(len(bin_edges)-1)\n",
    "\n",
    "    # Energy histogram is just g(U) x exp(-beta U)\n",
    "    for ibin, edge in enumerate(bin_edges[:-1]):\n",
    "        bin_energy = edge + 0.5*bin_width\n",
    "        prob[ibin] = m.exp(wl_logdos[ibin]-beta*bin_energy)\n",
    "\n",
    "    # Normalise\n",
    "    prob = prob/np.sum(prob*bin_width)\n",
    "\n",
    "    # Only plot every 5th histogram to avoid crowding the axes\n",
    "    if itemp%5 == 0:\n",
    "        strlabel = \"T={:1.2}\".format(new_temp)\n",
    "        ax1.bar(bin_edges[:-1], prob, width=bin_width, align='edge', label=strlabel)\n",
    "    \n",
    "    # Mean energy\n",
    "    mean_energy = np.dot(bin_edges[:-1]+0.5*bin_width, prob)/np.sum(prob)\n",
    "    mean_energies[itemp] = mean_energy\n",
    "\n",
    "    # Compute heat capacity using the histogram\n",
    "    msq_dev = np.zeros(len(bin_edges)-1)\n",
    "    for ibin, edge in enumerate(bin_edges[:-1]):\n",
    "        bin_energy = edge + 0.5*bin_width\n",
    "        msq_dev[ibin] = (bin_energy - mean_energies[itemp])**2\n",
    "        \n",
    "    heat_caps[itemp] = np.dot(msq_dev, prob)*bin_width/(new_temp**2) + (Ndims/2)*(Nbeads-1)\n",
    "\n",
    "\n",
    "# Complete plots using data computed above\n",
    "ax1.legend()\n",
    "ax2.errorbar(temperatures, mean_energies,yerr=mean_errors, fmt='-o')\n",
    "ax3.plot(temperatures, heat_caps, '-o', label='samples')\n",
    "plt.show()\n",
    "\n",
    "# Store heat_caps for comparison to alternative compuation below\n",
    "hist_heat_caps = heat_caps;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample reweighting\n",
    "\n",
    "This is all fine provided the only quanities I want to know at any temperature can be computed directly from the energy histogram. Any other quantities need to sampled during a WL run with *fixed* $g(u)$ along with the corresponding microstate energy $U$ so that we can give them an appropriate weight at the new temperature.\n",
    "\n",
    "In the following we'll record samples of both energy $U$ and end-to-end distance $L$ as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise wl_simulation with a fixed g(U)\n",
    "Ndims=2 ; Nbeads=7\n",
    "chain = polymer(Ndims = Ndims, Nbeads = Nbeads)\n",
    "\n",
    "# Define energy range and bins\n",
    "energy_range = [-6.1, 4.0]\n",
    "bin_edges = np.histogram_bin_edges(energy_range, bins=50)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "\n",
    "# Initialise histogram \n",
    "wl_hist   = np.zeros(len(bin_edges)-1)\n",
    "\n",
    "# Load DOS I made earlier - comment out to use those generated above\n",
    "#filename = 'data/dos_f4.8828125e-06.txt'\n",
    "#wl_logdos = np.loadtxt(filename)\n",
    "\n",
    "# No further modification to density of states\n",
    "wl_f = 0.0\n",
    "\n",
    "# Setup some plots\n",
    "%matplotlib widget\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 5))\n",
    "label_wl_figure(fig, ax1, ax2, wl_f)\n",
    "ax1.bar(bin_edges[:-1], wl_hist, width=bin_width, align='edge')\n",
    "ax2.plot(bin_edges[:-1]+0.5*bin_width, wl_logdos)\n",
    "fig.suptitle('Wang Landau sampling run', fontsize=16)\n",
    "ax2.set_title('Constant DOS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "Nframes = 5000 # number of frames to run with fixed weights\n",
    "\n",
    "# I like a progress bar\n",
    "f = IntProgress(min=0, max=Nframes)\n",
    "display(f) # display the bar\n",
    "\n",
    "# Initialise sampled quantities\n",
    "samples = []\n",
    "\n",
    "for iframe in range(Nframes):\n",
    "    \n",
    "\n",
    "    chain, new_samples, wl_hist, wl_logdos, ratio = run_wl_sweeps(chain, bin_edges, wl_hist, wl_logdos, wl_f, max_disp=0.1)\n",
    "    samples = samples + new_samples\n",
    "    f.value +=1  # Increment progress bar\n",
    "\n",
    "    # Update plots\n",
    "    ax1.cla(), ax2.cla()\n",
    "    ax1.bar(bin_edges[:-1], wl_hist,   width=bin_width,align='edge')\n",
    "    ax2.plot(bin_edges[:-1]+0.5*bin_width, wl_logdos)\n",
    "    label_wl_figure(fig, ax1, ax2, wl_f)\n",
    "    fig.suptitle('Wang Landau sampling run', fontsize=16)\n",
    "    ax1.set_title('Current histogram')\n",
    "    ax2.set_title('Constant DOS')\n",
    "    plt.draw()\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "    # Save histogram\n",
    "    #filename = 'data/histogram_f4.8828125e-06.txt'\n",
    "    #np.savetxt(filename, wl_hist)\n",
    "\n",
    "    # Save samples\n",
    "    #filename = 'data/samples_f4.8828125e-06.dat'\n",
    "    #FILE = open(filename,\"w\")\n",
    "    #samples.tofile(FILE)\n",
    "    #FILE.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the samples of end-to-end distance obtained in this simulation to compute averages at any temperature by giving the $i$th sample a weight of;\n",
    "\n",
    "$$ w_i = g(U_i) \\exp{[-\\beta U_i]} $$\n",
    "\n",
    "if we treat our estimate of $g(U)$ as perfect, or alternatively;\n",
    "\n",
    "$$ w_i = g(U_i) \\exp{[-\\beta U_i]}/\\tilde{P}(U_i) $$\n",
    "\n",
    "where $\\tilde{P}(U_i)$ is the multicanonical probability distribution we obtained with the fixed density of states estimate. In a perfect world this would be exactly flat and so wouldn't have any impact on the relative sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do something with the samples\n",
    "energy_samples  = [ sample[0] for sample in samples ]\n",
    "end2end_samples = [ sample[1] for sample in samples ]\n",
    "\n",
    "# End to end distance as a function of temperature\n",
    "temperatures = np.arange(0.1, 0.51, 0.01)\n",
    "\n",
    "# Array of average end-to-end distances\n",
    "mean_end2end = np.zeros(len(temperatures))\n",
    "\n",
    "# Loop over temperatures of interest\n",
    "for itemp, new_temp in enumerate(temperatures):\n",
    "\n",
    "    beta = 1.0/new_temp\n",
    "    \n",
    "    # Array of weights for every sample\n",
    "    weights = np.zeros(len(energy_samples))\n",
    "    \n",
    "    for isamp, sample_energy in enumerate(energy_samples):\n",
    "\n",
    "        ibin = bin_index(sample_energy, bin_edges)\n",
    "        edge = bin_edges[ibin]\n",
    "        bin_energy = edge + 0.5*bin_width\n",
    "        weights[isamp] = m.exp(wl_logdos[ibin]-beta*bin_energy)/wl_hist[ibin]\n",
    "\n",
    "    # Mean end to end distance is dot product of samples and weights\n",
    "    mean_end2end[itemp] = np.dot(end2end_samples, weights)/np.sum(weights)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "fig.clf()\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(temperatures, mean_end2end,'o-')\n",
    "ax.set_xlabel('Temperature T')\n",
    "ax.set_ylabel('<L>')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, we can also weight each sample of energy individually to compute (e.g.) heat capacity without using the discretised energies at the centre of the histogram bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat capacity as a function of temperature\n",
    "temperatures = np.arange(0.1,0.51,0.01)\n",
    "\n",
    "heat_cap = np.zeros(len(temperatures))\n",
    "\n",
    "for itemp, new_temp in enumerate(temperatures):\n",
    "    \n",
    "    beta = 1.0/new_temp\n",
    "    prob = np.zeros(len(bin_edges)-1)\n",
    "\n",
    "    # We use the bins only to determine the density of states estimate at the current sample energy\n",
    "    for isamp, sample_energy in enumerate(energy_samples):\n",
    "\n",
    "        ibin = bin_index(sample_energy, bin_edges)\n",
    "        edge = bin_edges[ibin]\n",
    "        bin_energy = edge + 0.5*bin_width\n",
    "        weights[isamp] = m.exp(wl_logdos[ibin]-beta*bin_energy)/wl_hist[ibin]    \n",
    "\n",
    "    mean_energy = np.dot(energy_samples, weights)/np.sum(weights)\n",
    "    delta_energy_sq = [(energy - mean_energy)**2 for energy in energy_samples]\n",
    "    mean_deltaE_sq = np.dot(delta_energy_sq, weights)/np.sum(weights)\n",
    "    \n",
    "    heat_cap[itemp] = mean_deltaE_sq/(new_temp**2) + (Ndims/2)*(Nbeads-1)\n",
    "\n",
    "# Plot and compare to that obtained by reweighting the histogram\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(temperatures, heat_cap,'-', label='Sample reweighting')\n",
    "plt.plot(temperatures, hist_heat_caps,'o', label='Computed direct from g(U)')\n",
    "ax.set_xlabel('Temperature T')\n",
    "ax.set_ylabel('Cv')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
