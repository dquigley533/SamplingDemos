{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition Matrix Monte Carlo (TMMC)\n",
    "[J. S. Wang and L. W. Lee, _Comp. Phys. Comm._ *127*, 131 (2000)](https://link.springer.com/article/10.1023/A:1013180330892)\n",
    "\n",
    "This approach attempts to address two deficiencies of other multicanonical sampling methods that \"visited states\" approaches.\n",
    "\n",
    "1. Information on sample distributions obtained during early MUCA or WL iterations with unrefined bias functions of density of states estimates is discarded and so (partially) wasted. \n",
    "\n",
    "2. Sample distributions obtained with visited stated methods are vulnerable to equilibration or \"burn in\", and can require long simulations such that the \"traversal\" time between the highest and lowest energies is very small compared to the total number of samples.\n",
    "\n",
    "This is improved by making use of the transition matrix approach. In this context the transition matrix $T$ is a square matrix with number of rows/columns equal to the number of energy macrostates (bins) we wish to sample. Element $T_ji$ is the probability that our Metropolis MC algorithm (as in e.g. `Basic_MMC.ipynb`) will make a transition from bin $i$ to bin $j$. \n",
    "\n",
    "An estimate of $T$ can be updated by updating a \"collection matrix\" with the probability for attempting and rejecting every Monte Carlo move we make during sampling. We can similarly run biased MC as in `MUCA.ipynb`, refining the weights however we like. Provided we update the collection matrix using only the _unbiased_ acceptance probabilities we'll create a collection matrix from which the ubiased transition matrix can be constructed.\n",
    "\n",
    "If we arrange the probabilities of obtaining a sample in each energy bin into a vector $\\vec{P}$, then this is evolved by the transition matrix as;\n",
    "\n",
    "$$ \\vec{P}^{\\prime} = T \\vec{P} $$\n",
    "\n",
    "where $\\vec{P}^{\\prime}$ is the evolved probabilities. By analagy with power iteration, repeatedly premultiplying $\\vec{P}$ with $T$ will result in $\\vec{P}^{\\prime}$ = $\\vec{P}$, i.e. the probability will evolve to an eigenvector of $T$ corresponding to the dominant eigenvalue. This is then the equilibrium probability distribution provided the trial moves used to construct $T$ obey detailed balance.\n",
    "\n",
    "A multicanonical sampling procudure would then be:\n",
    "\n",
    "1. Start running unbiased MC as in `Basic_MMC.ipynb`, adding to the collection matrix at every trial move using the _unbiased_ acceptance probabilities. \n",
    "2. Periodically use the collection matrix to estimate the transition matrix.\n",
    "3. Diagonalise the transition matrix and find the current estimate of equililibrium probability.\n",
    "4. Use this to construct MUCA bias $V(U)$ in the same way as in `MUCA.ipynb`\n",
    "5. Add this bias into the MC sampling. \n",
    "\n",
    "Steps 2-4 are repeated until we have an unchanging set of weights and probability distribution $P(U)$ obtained from the dominant eigenvector of $T$. This can be reweighted to other temperatures as in basic MUCA case.\n",
    "\n",
    "Note that at no point in the algorithm have we reset the collection matrix. Every MC move contributes from the first to the last. \n",
    "\n",
    "As an aside, a similar algorithm can be constructed for Wang-Landau sampling, where the dominant eigenvector of $T$ is the density of states in energy. I'll leave that as an exercise!\n",
    "\n",
    "TMMC applied to basic multicanonical sampling is demonstrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration on our simple bead and spring \"polymer\" model\n",
    "\n",
    "See `Basic_MMC.ipynb` and `polymer.py` for details of the model.\n",
    "\n",
    "### Import packages and create some binning functions functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polymer import *\n",
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_index(x, bin_edges):\n",
    "    \"\"\"Given a list of bin_edges returned from numpy.histogram, and a sampled value x, \n",
    "       return the index of the bin in which x lies. Note that np.digitize is annoying\n",
    "       and I don't like it.\n",
    "\n",
    "    Parameters:\n",
    "    x (float) : sample to assign to a bin\n",
    "    bin_edges : bin edges as returned from numpy.histogram \n",
    "\n",
    "    Returns:\n",
    "    i         : index of bin in which sample lies\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    bin_range = bin_edges[-1] - bin_edges[0]\n",
    "    bin_pos = x - bin_edges[0]\n",
    "\n",
    "    return int( (bin_pos/bin_range)*(len(bin_edges)-1.0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to construct bias $V(U)$ from the current transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_from_tm(tm, bin_edges, bin_width, temperature):\n",
    "    \"\"\"Given an collection matrix tm accumulated during a simulation at a particular temperature, \n",
    "       construct an estimate of the bias function needed to generated uniform sampling in \n",
    "       energy at that temperature.\n",
    "\n",
    "    Parameters:\n",
    "    tm                 : collection matrix (unnormalised transition matrix)\n",
    "    bin_edges          : energy bin edges as returned from numpy.histogram \n",
    "    bin_width          : width of each energy bin (assumes all bins equal width)\n",
    "    temperature        : temperature at which the collection matrix was \n",
    "\n",
    "    Returns:\n",
    "    new_bias           : estimated bias function\n",
    "    norm_tm            : the transition matrix\n",
    "    statP              : equilibrium distribution for the current transition matrix\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create transition matrix\n",
    "    nstates = len(bin_edges)-1\n",
    "    norm_tm = np.zeros([nstates,nstates])\n",
    "\n",
    "    # Compute as appropriately normalised collection matrix\n",
    "    for k in range(0, nstates):\n",
    "        Pnorm = np.sum(tm[:,k])\n",
    "        for kk in range(0, nstates):\n",
    "            if Pnorm > 0.0:\n",
    "                norm_tm[kk,k] = tm[kk,k]/Pnorm\n",
    "\n",
    "\n",
    "    # Find the dominant eigenvector and store as statP\n",
    "    eigvals, eigvects = np.linalg.eig(norm_tm)\n",
    "    idom = np.argmax(np.real(eigvals))\n",
    "    statP = np.absolute(eigvects[:,idom])\n",
    "\n",
    "    # In case there are bins for which we have no data (yet)\n",
    "    # replace zeros with minimum non-zero probability\n",
    "    mincount = np.min(statP[statP > 0.0])\n",
    "    statP = [ max(P,mincount) for P in statP]\n",
    "    statP = statP/np.sum(statP)\n",
    "\n",
    "    # Construct bias function needed for uniform energy sampling\n",
    "    new_bias = np.zeros(nstates)\n",
    "    for ibin, edge in enumerate(bin_edges[0:-1]):\n",
    "        bin_energy = edge + 0.5*bin_width\n",
    "        new_bias[ibin] = temperature*m.log(statP[ibin])\n",
    "\n",
    "    # Shift bias so that minimum value is zero\n",
    "    min_bias = np.min(new_bias)\n",
    "    new_bias = [bias - min_bias for bias in new_bias]\n",
    "    \n",
    "    return new_bias, norm_tm, statP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to implement TMMC for our polymer example\n",
    "\n",
    "This requires only minimal changes from that in MUCA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tmmc_sweeps(chain, bin_edges, bias, trans_matrix, Nsweeps=100, max_disp=0.15, temperature=0.2, sample_int=100):\n",
    "    \"\"\" Runs Nsweeps MC sweeps where one sweep is on average at attempt to move each mobile bead on the chain at least once.\n",
    "        Returns a  \"\"\"\n",
    "\n",
    "    # Store inverse temperature\n",
    "    beta = 1.0/temperature\n",
    "\n",
    "    # Initialise sampling for the current set of sweeps\n",
    "    samples = []\n",
    "    acount  = 0\n",
    "\n",
    "    # Establish total energy before any moves\n",
    "    old_energy = chain.energy()\n",
    "    \n",
    "    for itrial in range(Nsweeps*(chain.Nbeads-1)):\n",
    "\n",
    "        # Randomly choose any bead but the first\n",
    "        ibead = np.random.randint(1,chain.Nbeads) # first bead never moves\n",
    "\n",
    "        disp = 2.0*np.random.random_sample(2)-1.0\n",
    "        disp = disp*max_disp\n",
    "        \n",
    "        # Make trial move and compute energy change - note we only compute the terms \n",
    "        # in the energy which depend on ibead. See polymer.py\n",
    "        old_local_energy = chain.local_energy(ibead)\n",
    "        chain.rpos[ibead] = chain.rpos[ibead] + disp\n",
    "        new_local_energy = chain.local_energy(ibead)\n",
    "\n",
    "        # Find bias energy V for old_energy U before move\n",
    "        ibin = bin_index(old_energy, bin_edges)\n",
    "\n",
    "        # Find bias energy V for new_energy U after move\n",
    "        new_energy = old_energy + ( new_local_energy - old_local_energy )\n",
    "        jbin = bin_index(new_energy, bin_edges)\n",
    "\n",
    "        new_energy = old_energy + ( new_local_energy - old_local_energy )\n",
    "        jbin = bin_index(new_energy, bin_edges)\n",
    "\n",
    "        # (New for TMMC) probability of staying in the same bin, ignoring bias\n",
    "        trans_matrix[ibin,ibin] += 1.0 - min(1.0, m.exp(-beta*(new_local_energy - old_local_energy)))\n",
    "\n",
    "        # Only compute energy change if within limits where V is defined\n",
    "        if jbin in range (0, len(bias)):\n",
    "\n",
    "\n",
    "            # (New for TMMC) probability of moving to jbin, ignoring bias\n",
    "            trans_matrix[jbin,ibin] += min(1.0, m.exp(-beta*(new_local_energy - old_local_energy)))\n",
    "\n",
    "            # Add change in V into diff_energy\n",
    "            old_bias = bias[ibin]\n",
    "            new_bias = bias[jbin]         \n",
    "            diff_energy = (new_energy + new_bias) - (old_energy + old_bias)\n",
    "            \n",
    "            # Accept or reject move\n",
    "            if np.random.sample() < m.exp(-diff_energy*beta):\n",
    "                # accepted\n",
    "                acount = acount + 1.    # Accepted - increment counter\n",
    "                old_energy = new_energy # (New for MUCA) update old_energy for next move\n",
    "            else:\n",
    "                # # Restore original chain position \n",
    "                chain.rpos[ibead] = chain.rpos[ibead] - disp\n",
    "\n",
    "        else:\n",
    "            # reject and reset\n",
    "            chain.rpos[ibead] = chain.rpos[ibead] - disp\n",
    "        \n",
    "        # Sample energy and end-to-end distance every sample_int sweeps\n",
    "        if itrial%sample_int*(chain.Nbeads-1)==0:\n",
    "            samples.append((chain.energy(), chain.end2end()))\n",
    "\n",
    "        ratio = acount/(Nsweeps*(chain.Nbeads-1)) \n",
    "        \n",
    "    # (Modified for TMMC) return trans_matrix as well as other quantities\n",
    "    return chain, samples, trans_matrix, acount/(Nsweeps*(chain.Nbeads-1))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a simulation which uses the above to iteratively refine V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise TMMC simulation\n",
    "Ndims=2 ; Nbeads=7\n",
    "chain = polymer(Ndims = Ndims, Nbeads = Nbeads)\n",
    "\n",
    "# Define energy range and bins\n",
    "energy_range = [-6.1, 4.0]\n",
    "bin_edges = np.histogram_bin_edges(energy_range, bins=50)\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "\n",
    "# Create initial bias function, histogram and transition matrix, and TM eigenvalue\n",
    "bias = np.zeros(len(bin_edges)-1)\n",
    "histogram = np.zeros(len(bin_edges)-1)\n",
    "trans_matrix = np.zeros([len(bin_edges)-1,len(bin_edges)])\n",
    "norm_tm = np.copy(trans_matrix)\n",
    "statP = np.zeros(len(bin_edges)-1)\n",
    "\n",
    "# Setup some plots\n",
    "%matplotlib widget\n",
    "\n",
    "def label_tmmc_figure(fig, ax1, ax2, ax3):\n",
    "    \"\"\" Sets up figures and axis for TMMC demonstration \"\"\"\n",
    "\n",
    "    ax1.set_xlabel('Energy U')\n",
    "    ax2.set_xlabel('Energy U')\n",
    "    ax1.set_ylabel('Histogram P(U)')\n",
    "    ax2.set_ylabel('Bias V(U)')\n",
    "    ax1.set_title('Current histogram')\n",
    "    ax2.set_title('Current MUCA bias')\n",
    "    ax3.set_title('Current transition matrix')\n",
    "\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(1, 3, figsize=(11, 4), constrained_layout=True)\n",
    "label_tmmc_figure(fig, ax1, ax2, ax3)\n",
    "ax1.bar(bin_edges[:-1], histogram,   width=bin_width,align='edge')\n",
    "ax2.plot(bin_edges[:-1]+0.5*bin_width, bias)\n",
    "ax3.imshow(trans_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "temp = 0.4     # Temperature at which to sample\n",
    "Ncycles=  5    # Bias update cycles\n",
    "Nframes = 1000 # Number frames per bias update cycle\n",
    "\n",
    "\n",
    "# If starting from an existing bias function\n",
    "#filename = 'data/muca_bias_N7T0.4_cycle_49.txt'\n",
    "#bias = np.loadtxt(filename)\n",
    "#initial_bias = np.copy(bias)\n",
    "\n",
    "# Loop over updates of the weights\n",
    "for icyc in range(Ncycles):\n",
    "\n",
    "    # I like a progress bar\n",
    "    f = IntProgress(min=0, max=Nframes)\n",
    "    display(f) # display the bar\n",
    "\n",
    "    # Initialise list of samples for current cycle\n",
    "    samples = []\n",
    "\n",
    "    # Zero current visited states histogram\n",
    "    histogram = np.zeros(len(bin_edges)-1)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "    for iframe in range(Nframes):\n",
    "\n",
    "        chain, new_samples, trans_matrix, ratio = run_tmmc_sweeps(chain, bin_edges, bias, trans_matrix, max_disp=0.1, temperature=temp)\n",
    "        samples += new_samples\n",
    "        f.value +=1  # Increment progress bar\n",
    "\n",
    "        energy_samples  = [ sample[0] for sample in samples ]\n",
    "        counts, bins = np.histogram(energy_samples, bins=bin_edges, density=True)\n",
    "\n",
    "        # Update plots\n",
    "        ax1.cla(), ax2.cla(); ax3.cla()\n",
    "        label_tmmc_figure(fig, ax1, ax2, ax3)\n",
    "        ax1.bar(bin_edges[:-1], counts, width=bin_width,align='edge', label='Visited states')\n",
    "        ax1.plot(bin_edges[:-1]-bin_width, statP/bin_width, 'r-', label='TM Eigenvector')\n",
    "        ax2.plot(bin_edges[:-1]+0.5*bin_width, bias,'o-')\n",
    "        #ax2.plot(bin_edges[:-1]+0.5*bin_width, initial_bias,'-')\n",
    "        ax3.imshow(norm_tm)\n",
    "        ax1.legend()\n",
    "        plt.draw()\n",
    "    \n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "\n",
    "\n",
    "    print(\"Accepted \",round(ratio*100,2),\"% of trial moves\")\n",
    "    \n",
    "    # Compute new bias weights from transition matrix\n",
    "    bias, norm_tm, statP = bias_from_tm(trans_matrix, bin_edges, bin_width, temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram reweighting\n",
    "\n",
    "As we've sampled the entire energy range of interest, we don't need to limit ourselves to a single temperature. If the MUCA simulation was performed at a temperature of $T_1$, inverse temperature $\\beta_1=1/k_B T_1$ then we can reweight each entry in the transition matrix eigenvector with\n",
    "\n",
    "$$ w_i = \\exp{[(\\beta_1 -\\beta_2) U_i]}  $$\n",
    "\n",
    "where $U_i$ is the mid-bin energy to obtain the histogram for inverse temperature $\\beta_2$ and hence temperature $T_2 = 1/\\beta_2$.  From this we can compute mean energy, heat capacity etc as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperatures of interest - we can make this as fine as we like since each temperature no longer requires\n",
    "# a new simulation to sample.\n",
    "#temperatures = np.arange(0.1, 0.55, 0.05)\n",
    "temperatures = np.arange(0.1, 0.51, 0.01)\n",
    "orig_temp = 0.4\n",
    "beta_o = 1.0/orig_temp\n",
    "\n",
    "# Setup plots\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(1, 3, figsize=(12, 4), constrained_layout=True)\n",
    "\n",
    "ax1.set_xlabel('energy U')\n",
    "ax1.set_ylabel('P(U)')\n",
    "ax1.set_title(\"MUCA energy histograms\")\n",
    "\n",
    "ax2.set_xlabel('temperature T')\n",
    "ax2.set_ylabel('<U>')\n",
    "ax2.set_title('Mean energy vs temperature')  \n",
    "\n",
    "ax3.set_xlabel('temperature T')\n",
    "ax3.set_ylabel('Cv')\n",
    "ax3.set_title('Heat capacity vs temperature') \n",
    "\n",
    "# Initialise arrays \n",
    "mean_energies   = np.zeros(len(temperatures))\n",
    "mean_errors     = np.zeros(len(temperatures))\n",
    "heat_caps       = np.zeros(len(temperatures))\n",
    "#heat_caps2      = np.zeros(len(temperatures))\n",
    "\n",
    "# Loop over temperatures of interest\n",
    "for itemp, new_temp in enumerate(temperatures):\n",
    "\n",
    "    beta_n = 1.0/new_temp\n",
    "\n",
    "    # Reweighted histogram\n",
    "    prob = np.zeros(len(bin_edges)-1)\n",
    "    \n",
    "    # Reweight histogram\n",
    "    for ibin, edge in enumerate(bin_edges[:-1]):\n",
    "        bin_energy = edge + 0.5*bin_width\n",
    "        weight = m.exp((beta_o - beta_n)*bin_energy)\n",
    "        prob[ibin] = statP[ibin]*weight\n",
    "\n",
    "    # Normalise\n",
    "    prob = prob/(np.sum(prob)*bin_width)\n",
    "\n",
    "    # Only plot every 5th histogram to avoid crowding the axes\n",
    "    if itemp%5 == 0:\n",
    "        strlabel = \"T={:1.2}\".format(new_temp)\n",
    "        ax1.bar(bin_edges[:-1], prob, width=bin_width, align='edge', label=strlabel)\n",
    "    \n",
    "    # Mean energy\n",
    "    mean_energy = np.dot(bin_edges[:-1]+0.5*bin_width, prob)/np.sum(prob)\n",
    "    mean_energies[itemp] = mean_energy\n",
    "\n",
    "    # Compute heat capacity using the histogram\n",
    "    msq_dev = np.zeros(len(bin_edges)-1)\n",
    "    for ibin, edge in enumerate(bin_edges[:-1]):\n",
    "        bin_energy = edge + 0.5*bin_width\n",
    "        msq_dev[ibin] = (bin_energy - mean_energies[itemp])**2\n",
    "        \n",
    "    heat_caps[itemp] = np.dot(msq_dev, prob)*bin_width/(new_temp**2) + (Ndims/2)*(Nbeads-1)\n",
    "\n",
    "\n",
    "# Complete plots using data computed above\n",
    "ax1.legend()\n",
    "ax2.errorbar(temperatures, mean_energies,yerr=mean_errors, fmt='-o')\n",
    "ax3.plot(temperatures, heat_caps, '-o', label='samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample reweighting\n",
    "\n",
    "This is all fine provided the only quanities I want to know at any temperature can be computed directly from the energy histogram. Any other quantities need to sampled during a MUCA run with a fixed bias energy along with the corresponding microstate energy $U$ so that we can give them an appropriate weight at the new temperature and to remove the effect of the bias $V(U)$. \n",
    "\n",
    "This proceeds exactly as per the sample run with fixed weights in `MUCA.ipynb` only now the fixed weights used are those constructed from the transition matrix. We won't bother repeating that exercise here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
